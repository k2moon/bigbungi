{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMuQKRfgldv5bBfHfq0amEl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/k2moon/bigbungi/blob/main/test/bigbungi_work02_classifier_01_ex.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 작업형 ▶ 제2유형  분류 모델 수행하기\n",
        "---\n"
      ],
      "metadata": {
        "id": "C9HN8YvV8cKL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 캐글 타이타닉 생존 여부 예측\n",
        "\n",
        "다음은 Titanic - Machine Learning from Disaster 데이터 세트이다. 주어진 훈련 데이터 세트를 활용하여 생존 여부를 예측하고 해당 결과를 csv파일로 제출하시오.\n",
        "(제출한 모델의 성능은 ROC-AUC 평가지표에 따라 채점)\n",
        "\n",
        "* 결과 제출 양식 : PassengerId, Survived"
      ],
      "metadata": {
        "id": "Pg9j_GVZ9fz7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- DataSet: https://www.kaggle.com/competitions/titanic\n",
        "- DataSet x_test : https://tinyurl.com/yew5uc73\n",
        "- DataSet x_train : https://tinyurl.com/37jrwyay\n",
        "- DataSet y_train : https://tinyurl.com/3r5hmh84"
      ],
      "metadata": {
        "id": "9JHqFFKDOxQd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 가져오기 read_csv()\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "x_test = pd.read_csv(\"https://tinyurl.com/yew5uc73\", encoding='CP949')\n",
        "x_train = pd.read_csv(\"https://tinyurl.com/37jrwyay\", encoding='CP949')\n",
        "y_train = pd.read_csv(\"https://tinyurl.com/3r5hmh84\")"
      ],
      "metadata": {
        "id": "xqtil__a5QDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 값 확인\n"
      ],
      "metadata": {
        "id": "XdqPyWDJ8nIr"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HEIV-WsmrS4y"
      },
      "outputs": [],
      "source": [
        "# ------- 데이터 확인 및 EDA ---------\n",
        "\n",
        "\n",
        "# 모든 컬럼값 확인 T\n",
        "\n",
        "\n",
        "# 행/열 확인 shape (생략가능)\n",
        "\n",
        "\n",
        "# 요약정보 확인 info()\n",
        "## 데이터타입, 결측치 등 확인, object 범주형\n",
        "### object 범주형 인코딩 확인\n",
        "\n",
        "\n",
        "# 기초통계량 확인 describe()\n",
        "## count, mean,std,min, 25%, 50%, 75%, max\n",
        "### 데이터 스케일링 확인, 회귀, 비tree 계열\n",
        "\n",
        "\n",
        "# 타깃값 확인 unique\n",
        "## 1차원인지도 확인 (y,)\n",
        "\n",
        "\n",
        "# ------- 데이터 전처리 preprocessing ---------\n",
        "\n",
        "# 불필요한 컬럭 삭제 drop(columns=[])\n",
        "## PK 역할 컬럼 등 삭제\n",
        "\n",
        "\n",
        "# 결측치 처리하기 fillna()\n",
        "## 임의로 결측치 삭제하지 말 것\n",
        "## 평균, 중앙값, 상황에 따른 값\n",
        "\n",
        "\n",
        "# 범주형 변수 인코딩\n",
        "## 라벨 인코딩 LabelEncoder, 원핫인코딩  OneHotEncoder\n",
        "## 라벨 인코딩(Tree 계열의 분류 알고리즘에 사용)\n",
        "\n",
        "\n",
        "# 파생변수 생성\n",
        "## 필요시 생성\n",
        "\n",
        "\n",
        "# 데이터 스케일링\n",
        "## 연속형 변수의 최대, 최소 분포차가 클때\n",
        "## MinMaxScaler, StandardScaler, RobustScaler\n",
        "## test는 train용의로 transform() \n",
        "## Tree 계열 필수는 아님\n",
        "\n",
        "\n",
        "# 상관관계 확인 corr()\n",
        "## 필요 시 확인\n",
        "\n",
        "\n",
        "# 전처리 확인 info()\n",
        "\n",
        "\n",
        "# ------- 머신러닝 machine learning ---------\n",
        "\n",
        "# 평가용 데이터 분리 model_selection\n",
        "## stratify, stes_size, y값 1차원 확인\n",
        "\n",
        "\n",
        "# 데이터 학습\n",
        "## fit, predict, predict_proba\n",
        "## 분류 XXXClassifier, LogisticRegression\n",
        "## 회귀(예측) XXXRegressor(XXXRegression)\n",
        "## 공통 ensemble\n",
        "## RandomForestXXX : n_estimators (default = 100), max_depth, criterion\n",
        "## criterion : 분할 품질을 측정하는 기능 ()\n",
        "### RandomForestClassifier: criterion{“gini”, “entropy”, “log_loss”}, default=”gini”\n",
        "### RandomForestRegressor: criterion{“mse”, “mae”}, / v1.2 criterion{“squared_error”, “absolute_error”}, default=”squared_error”\n",
        "## GradientBoostingXXX : n_estimators, learning_rate(default =  0.1)\n",
        "\n",
        "\n",
        "# 데이터 평가 metrics\n",
        "## 회귀 : MAE, MSE, RMSE, R^2, RMSE는 np.sqrt(MSE값)\n",
        "## 분류 : ROC_AUC, Accuracy(정확도), Precision(정밀도), Recall(재현율)\n",
        "\n",
        "\n",
        "# ------- 답안 제출 ---------\n",
        "\n",
        "# 전체학습데이터로 다시 학습\n",
        "\n",
        "\n",
        "# 제출용 예측\n",
        "\n",
        "\n",
        "# 답안 제출 참고\n",
        "# 아래 코드 예측변수와 수험번호를 개인별로 변경하여 활용\n",
        "#pd.DataFrame({'cust_id': x_test_data.cust_id, 'gender': pred}).to_csv('424242.csv', index=False)\n",
        "\n",
        "\n",
        "# 제출 최종 확인\n",
        "#print(pd.read_csv(\"data/424242.csv\"))"
      ]
    }
  ]
}