{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPq15xmvoxfzdJ7UEQaIZkj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/k2moon/bigbungi/blob/main/test/bigbungi_work02_classifier_01_ans.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 작업형 ▶ 제2유형  분류 모델 수행하기\n",
        "---\n"
      ],
      "metadata": {
        "id": "C9HN8YvV8cKL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 캐글 타이타닉 생존 여부 예측\n",
        "\n",
        "다음은 Titanic - Machine Learning from Disaster 데이터 세트이다. 주어진 훈련 데이터 세트를 활용하여 생존 여부를 예측하고 해당 결과를 csv파일로 제출하시오.\n",
        "(제출한 모델의 성능은 ROC-AUC 평가지표에 따라 채점)\n",
        "\n",
        "* 결과 제출 양식 : PassengerId, Survived"
      ],
      "metadata": {
        "id": "Pg9j_GVZ9fz7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- DataSet: https://www.kaggle.com/competitions/titanic\n",
        "- DataSet x_test : https://tinyurl.com/yew5uc73\n",
        "- DataSet x_train : https://tinyurl.com/37jrwyay\n",
        "- DataSet y_train : https://tinyurl.com/3r5hmh84"
      ],
      "metadata": {
        "id": "9JHqFFKDOxQd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 가져오기 read_csv()\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "x_test = pd.read_csv(\"https://tinyurl.com/yew5uc73\", encoding='CP949')\n",
        "x_train = pd.read_csv(\"https://tinyurl.com/37jrwyay\", encoding='CP949')\n",
        "y_train = pd.read_csv(\"https://tinyurl.com/3r5hmh84\")"
      ],
      "metadata": {
        "id": "xqtil__a5QDX"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 값 확인\n",
        "x_train.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdqPyWDJ8nIr",
        "outputId": "a4287ae9-b496-4db7-b8c1-49a1abcddaa9"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "티켓등급    0\n",
              "성별      0\n",
              "운임요금    0\n",
              "선착장     0\n",
              "가족수     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "HEIV-WsmrS4y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9c7e7008-6d25-4795-a7f8-8ed0fef2b22b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                   0\n",
            "PassengerId                        1\n",
            "티켓등급                               3\n",
            "승객이름         Braund, Mr. Owen Harris\n",
            "성별                              male\n",
            "나이                              22.0\n",
            "형제자매배우자수                           1\n",
            "부모자식수                              0\n",
            "티켓번호                       A/5 21171\n",
            "운임요금                            7.25\n",
            "객실번호                             NaN\n",
            "선착장                                S\n",
            "(891, 11)\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 11 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   티켓등급         891 non-null    int64  \n",
            " 2   승객이름         891 non-null    object \n",
            " 3   성별           891 non-null    object \n",
            " 4   나이           714 non-null    float64\n",
            " 5   형제자매배우자수     891 non-null    int64  \n",
            " 6   부모자식수        891 non-null    int64  \n",
            " 7   티켓번호         891 non-null    object \n",
            " 8   운임요금         891 non-null    float64\n",
            " 9   객실번호         204 non-null    object \n",
            " 10  선착장          889 non-null    object \n",
            "dtypes: float64(2), int64(4), object(5)\n",
            "memory usage: 76.7+ KB\n",
            "None\n",
            "       PassengerId        티켓등급          나이    형제자매배우자수       부모자식수        운임요금\n",
            "count   891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
            "mean    446.000000    2.308642   29.699118    0.523008    0.381594   32.204208\n",
            "std     257.353842    0.836071   14.526497    1.102743    0.806057   49.693429\n",
            "min       1.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
            "25%     223.500000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
            "50%     446.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
            "75%     668.500000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
            "max     891.000000    3.000000   80.000000    8.000000    6.000000  512.329200\n",
            "0    549\n",
            "1    342\n",
            "Name: Survived, dtype: int64\n",
            "[0 1]\n",
            "성별\n",
            "female    0.742038\n",
            "male      0.188908\n",
            "Name: Survived, dtype: float64\n",
            "티켓등급\n",
            "1    0.629630\n",
            "2    0.472826\n",
            "3    0.242363\n",
            "Name: Survived, dtype: float64\n",
            "선착장\n",
            "C    0.553571\n",
            "Q    0.389610\n",
            "S    0.336957\n",
            "Name: Survived, dtype: float64\n",
            "티켓등급          0\n",
            "승객이름          0\n",
            "성별            0\n",
            "나이          177\n",
            "형제자매배우자수      0\n",
            "부모자식수         0\n",
            "티켓번호          0\n",
            "운임요금          0\n",
            "객실번호        687\n",
            "선착장           2\n",
            "dtype: int64\n",
            "티켓등급          0\n",
            "성별            0\n",
            "나이          177\n",
            "형제자매배우자수      0\n",
            "부모자식수         0\n",
            "운임요금          0\n",
            "선착장           2\n",
            "dtype: int64\n",
            "                나이  Survived\n",
            "나이        1.000000 -0.077221\n",
            "Survived -0.077221  1.000000\n",
            "['male' 'female']\n",
            "[1 0]\n",
            "[1 0]\n",
            "[1 2 0]\n",
            "      count       mean        std  min     25%      50%   75%       max\n",
            "티켓등급  891.0   2.308642   0.836071  1.0  2.0000   3.0000   3.0    3.0000\n",
            "성별    891.0   0.647587   0.477990  0.0  0.0000   1.0000   1.0    1.0000\n",
            "운임요금  891.0  32.204208  49.693429  0.0  7.9104  14.4542  31.0  512.3292\n",
            "선착장   891.0   1.538721   0.794231  0.0  1.0000   2.0000   2.0    3.0000\n",
            "가족수   891.0   0.904602   1.613459  0.0  0.0000   0.0000   1.0   10.0000\n",
            "      count          mean       std       min       25%       50%       75%  \\\n",
            "티켓등급  891.0 -8.772133e-17  1.000562 -1.566107 -0.369365  0.827377  0.827377   \n",
            "성별    891.0 -1.156327e-16  1.000562 -1.355574 -1.355574  0.737695  0.737695   \n",
            "운임요금  891.0  3.987333e-18  1.000562 -0.648422 -0.489148 -0.357391 -0.024246   \n",
            "선착장   891.0 -3.588600e-17  1.000562 -1.938460 -0.678673  0.581114  0.581114   \n",
            "가족수   891.0 -3.987333e-18  1.000562 -0.560975 -0.560975 -0.560975  0.059160   \n",
            "\n",
            "           max  \n",
            "티켓등급  0.827377  \n",
            "성별    0.737695  \n",
            "운임요금  9.667167  \n",
            "선착장   1.840901  \n",
            "가족수   5.640372  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 5 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   티켓등급    891 non-null    float64\n",
            " 1   성별      891 non-null    float64\n",
            " 2   운임요금    891 non-null    float64\n",
            " 3   선착장     891 non-null    float64\n",
            " 4   가족수     891 non-null    float64\n",
            "dtypes: float64(5)\n",
            "memory usage: 34.9 KB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 418 entries, 0 to 417\n",
            "Data columns (total 5 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   티켓등급    418 non-null    float64\n",
            " 1   성별      418 non-null    float64\n",
            " 2   운임요금    417 non-null    float64\n",
            " 3   선착장     418 non-null    float64\n",
            " 4   가족수     418 non-null    float64\n",
            "dtypes: float64(5)\n",
            "memory usage: 16.5 KB\n",
            "None\n",
            "0    0.616162\n",
            "1    0.383838\n",
            "Name: Survived, dtype: float64\n",
            "0    0.616573\n",
            "1    0.383427\n",
            "Name: Survived, dtype: float64\n",
            "0.8140316205533596\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-a001c9c054ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;31m# 제출용 예측\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    806\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m         \"\"\"\n\u001b[0;32m--> 808\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    848\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 850\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    577\u001b[0m         Validate X whenever one tries to predict, apply, predict_proba.\"\"\"\n\u001b[1;32m    578\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintc\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No support for np.int64 index based sparse matrices\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"allow-nan\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    114\u001b[0m             raise ValueError(\n\u001b[1;32m    115\u001b[0m                 msg_err.format(\n\u001b[0;32m--> 116\u001b[0;31m                     \u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m                 )\n\u001b[1;32m    118\u001b[0m             )\n",
            "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
          ]
        }
      ],
      "source": [
        "# ------- 데이터 확인 및 EDA ---------\n",
        "\n",
        "# 모든 컬럼값 확인 T\n",
        "print(x_train.head(1).T)\n",
        "\n",
        "# 행/열 확인 shape (생략가능)\n",
        "print(x_train.shape)\n",
        "\n",
        "# 요약정보 확인 info()\n",
        "## 데이터타입, 결측치 등 확인, object 범주형\n",
        "### object 범주형 인코딩 확인\n",
        "print(x_train.info())\n",
        "\n",
        "# 기초통계량 확인 describe()\n",
        "## count, mean,std,min, 25%, 50%, 75%, max\n",
        "## 데이터 스케일링 확인, 회귀, 비tree 계열\n",
        "print(x_train.describe())\n",
        "#print(X_train.describe().loc['min',:])\n",
        "\n",
        "# 타깃값 확인 unique\n",
        "## 1차원인지도 확인 (y,)\n",
        "print(y_train['Survived'].value_counts())\n",
        "y_train = y_train['Survived']\n",
        "print(y_train.unique())\n",
        "\n",
        "# EDA\n",
        "data = pd.concat([x_train, y_train], axis=1)\n",
        "\n",
        "## 성별 칼럼에 따른 생존 Survived 평균값\n",
        "print(data.groupby(['성별'])['Survived'].mean())\n",
        "\n",
        "## 티켓등급 칼럼에 따른 생존 Survived 평균값\n",
        "print(data.groupby(['티켓등급'])['Survived'].mean())\n",
        "\n",
        "## 선착장 칼럼에 따른 생존 Survived 평균값\n",
        "print(data.groupby(['선착장'])['Survived'].mean())\n",
        "\n",
        "# ------- 데이터 전처리 preprocessing ---------\n",
        "## train, test 모두 처리 해야 함\n",
        "\n",
        "# 불필요한 컬럭 삭제 drop(columns=[])\n",
        "## PK 역할 컬럼 등 삭제\n",
        "x_train = x_train.drop(columns = ['PassengerId'])\n",
        "y_train = y_train.drop(columns = ['PassengerId'])\n",
        "\n",
        "# 제출용 id 삭제전 저장\n",
        "x_test_id = x_test['PassengerId']\n",
        "x_test = x_test.drop(columns = ['PassengerId'])\n",
        "\n",
        "print(x_train.isnull().sum()) # 티켓번호,객실번호,승객이름 삭제 이유는?\n",
        "x_train = x_train.drop(columns=['티켓번호'])\n",
        "x_test = x_test.drop(columns=['티켓번호'])\n",
        "x_train = x_train.drop(columns=['객실번호'])\n",
        "x_test = x_test.drop(columns=['객실번호'])\n",
        "x_train = x_train.drop(columns=['승객이름'])\n",
        "x_test = x_test.drop(columns=['승객이름'])\n",
        "print(x_train.isnull().sum())\n",
        "\n",
        "\n",
        "# 결측치 처리하기 fillna()\n",
        "## 임의로 결측치 삭제하지 말 것\n",
        "## 평균, 중앙값, 상황에 따른 값\n",
        "## 나이, 선착장\n",
        "\n",
        "## 나이 상관관계 확인 - 상관이 없음 - 삭제\n",
        "print(data[['나이','Survived']].corr())\n",
        "x_train = x_train.drop(columns=['나이'])\n",
        "x_test = x_test.drop(columns=['나이'])\n",
        "## 나이 상황에 따른 값으로 처리 해도 됨 - 평균 등\n",
        "\n",
        "## 선착장 2건 상황에 따른 값으로 처리 - 평균, 최빈값\n",
        "v = x_train['선착장'].value_counts()\n",
        "\n",
        "x_train['선착장'] = x_train['선착장'].fillna(v)\n",
        "x_test['선착장'] = x_test['선착장'].fillna(v)\n",
        "\n",
        "\n",
        "# 범주형 변수 인코딩 objedt형\n",
        "## 라벨 인코딩 LabelEncoder, 원핫인코딩  OneHotEncoder\n",
        "## 라벨 인코딩(Tree 계열의 분류 알고리즘에 사용)\n",
        "## 성별, 선착장\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "print(x_train['성별'].unique())\n",
        "x_train['성별'] = encoder.fit_transform(x_train['성별'])\n",
        "x_test['성별'] = encoder.fit_transform(x_test['성별'])\n",
        "print(x_train['성별'].unique())\n",
        "print(x_test['성별'].unique())\n",
        "x_train['선착장'] = encoder.fit_transform(x_train['선착장'])\n",
        "x_test['선착장'] = encoder.fit_transform(x_test['선착장'])\n",
        "print(x_test['선착장'].unique())\n",
        "\n",
        "# 파생변수 생성\n",
        "## 필요시 생성\n",
        "## 유사 칼럼 : 부모자식수, 형제자매배우자수  => 가족수 만들기\n",
        "x_train['가족수'] = x_train['부모자식수'] + x_train['형제자매배우자수']\n",
        "x_train = x_train.drop(columns=['부모자식수', '형제자매배우자수'])\n",
        "\n",
        "x_test['가족수'] = x_test['부모자식수'] + x_test['형제자매배우자수']\n",
        "x_test = x_test.drop(columns=['부모자식수', '형제자매배우자수'])\n",
        "\n",
        "# 데이터 스케일링\n",
        "## 연속형 변수의 최대, 최소 분포차가 클때\n",
        "## MinMaxScaler, StandardScaler, RobustScaler\n",
        "## test는 train용으로 transform()\n",
        "## Tree 계열 필수는 아님\n",
        "\n",
        "print(x_train.describe().T)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "x_train = pd.DataFrame(scaler.fit_transform(x_train), columns=x_train.columns)\n",
        "x_test = pd.DataFrame(scaler.transform(x_test), columns=x_test.columns)\n",
        "print(x_train.describe().T)\n",
        "\n",
        "# 상관관계 확인 corr()\n",
        "## 필요 시 확인\n",
        "\n",
        "# 전처리 확인 info()\n",
        "print(x_train.info())\n",
        "print(x_test.info())\n",
        "\n",
        "# ------- 머신러닝 machine learning ---------\n",
        "\n",
        "# 평가용 데이터 분리 model_selection\n",
        "## stratify, stes_size, y값 1차원 확인\n",
        "print(y_train.value_counts()/len(y_train))\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(x_train, y_train, test_size=0.2, stratify=y_train)\n",
        "print(Y_train.value_counts()/len(Y_train))\n",
        "\n",
        "# 데이터 학습\n",
        "## fit, predict, predict_proba\n",
        "## 분류 XXXClassifier, LogisticRegression\n",
        "## 회귀(예측) XXXRegressor(XXXRegression)\n",
        "## 공통 ensemble\n",
        "## RandomForestXXX : n_estimators (default = 100), max_depth, criterion\n",
        "## criterion : 분할 품질을 측정하는 기능 ()\n",
        "### RandomForestClassifier: criterion{“gini”, “entropy”, “log_loss”}, default=”gini”\n",
        "### RandomForestRegressor: criterion{“mse”, “mae”}, / v1.2 criterion{“squared_error”, “absolute_error”}, default=”squared_error”\n",
        "## GradientBoostingXXX : n_estimators, learning_rate(default =  0.1)\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "\n",
        "#model = DecisionTreeClassifier(random_state=42) \n",
        "#model = LogisticRegression(random_state=42) \n",
        "model = RandomForestClassifier(random_state=42)  \n",
        "#model = GradientBoostingClassifier() \n",
        "\n",
        "model.fit(X_train, Y_train)\n",
        "pred = model.predict(X_test)\n",
        "\n",
        "\n",
        "# 데이터 평가 metrics\n",
        "## 회귀 : MAE, MSE, RMSE, R^2, RMSE는 np.sqrt(MSE값)\n",
        "## 분류 : ROC_AUC, Accuracy(정확도), Precision(정밀도), Recall(재현율)\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "print(roc_auc_score(Y_test, pred))\n",
        "\n",
        "\n",
        "# ------- 답안 제출 ---------\n",
        "\n",
        "# 전체학습데이터로 다시 학습\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# 제출용 예측\n",
        "pred = model.predict(x_test)\n",
        "\n",
        "\n",
        "# 답안 제출 참고\n",
        "# #아래 코드 예측변수와 수험번호를 개인별로 변경하여 활용\n",
        "#pd.DataFrame({'cust_id': x_test_data.cust_id, 'gender': pred}).to_csv('424242.csv', index=False)\n",
        "\n",
        "# 제출 최종 확인\n",
        "#print(pd.read_csv(\"data/424242.csv\"))"
      ]
    }
  ]
}