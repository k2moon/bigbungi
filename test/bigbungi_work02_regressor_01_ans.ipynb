{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPzsfZyLbEOJCCiHJOIQWro",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/k2moon/bigbungi/blob/main/test/bigbungi_work02_regressor_01_ans.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 작업형 ▶ 제2유형 회귀(예측) 모델 수행하기\n",
        "---\n"
      ],
      "metadata": {
        "id": "C9HN8YvV8cKL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 캐글 바이크 수요 예측\n",
        "\n",
        "다음은 Bike Sharing Demand 데이터 세트이다. 주어진 훈련 데이터 세트를 활용하여 대여량를 예측하고 해당 결과를 csv파일로 제출하시오.\n",
        "(제출한 모델의 성능은 R^2 score 평가지표에 따라 채점)\n",
        "\n",
        "* 결과 제출 양식 : PassengerId, Survived"
      ],
      "metadata": {
        "id": "Pg9j_GVZ9fz7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Kaggle: https://www.kaggle.com/competitions/bike-sharing-demand\n",
        "- DataSet x_test : https://tinyurl.com/2fucdhv3\n",
        "- DataSet x_train : https://tinyurl.com/4vy3adv5\n",
        "- DataSet y_train : https://tinyurl.com/vr9m327a"
      ],
      "metadata": {
        "id": "9JHqFFKDOxQd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 계절 : 1 봄, 2 여름, 3 가을, 4 겨울\n",
        "- 공휴일 : 1 공휴일, 0 평일\n",
        "- 근무일 : 1 근무일, 0 휴일\n",
        "- 날씨 : 1 아주 깨끗, 2 안개와 구름, 3 약간 눈 또는 비, 천둥 번개, 4 아주 많은 비 또는 우박"
      ],
      "metadata": {
        "id": "eKKf5n-FrDQc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 가져오기 read_csv()\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "x_test = pd.read_csv(\"https://tinyurl.com/2fucdhv3\", encoding='CP949')\n",
        "# 시간당 자전거 대여량 데이터\n",
        "x_train = pd.read_csv(\"https://tinyurl.com/4vy3adv5\", encoding='CP949')\n",
        "y_train = pd.read_csv(\"https://tinyurl.com/vr9m327a\")"
      ],
      "metadata": {
        "id": "xqtil__a5QDX"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 값 확인\n",
        "pred[pred < 0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdqPyWDJ8nIr",
        "outputId": "e4c98805-e3dd-4c25-eff5-087c31fa0637"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([], dtype=float64)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEIV-WsmrS4y"
      },
      "outputs": [],
      "source": [
        "# ------- 데이터 확인 및 EDA ---------\n",
        "\n",
        "# 모든 컬럼값 확인 T\n",
        "print(x_train.head(1).T)\n",
        "\n",
        "# 행/열 확인 shape (생략가능)\n",
        "print(x_train.shape)\n",
        "\n",
        "# 요약정보 확인 info()\n",
        "## 데이터타입, 결측치 등 확인, object 범주형\n",
        "## object 범주형 인코딩 확인\n",
        "print(x_train.info())\n",
        "print(x_train['계절'].unique())\n",
        "\n",
        "# 기초통계량 확인 describe()\n",
        "## count, mean,std,min, 25%, 50%, 75%, max\n",
        "## 데이터 스케일링 확인, 회귀, 비tree 계열\n",
        "print(x_train.describe())\n",
        "#print(X_train.describe().loc['min',:])\n",
        "\n",
        "# 타깃값 확인 unique\n",
        "## 1차원인지도 확인 (y,)\n",
        "print(y_train['count'].value_counts())\n",
        "y_train = y_train['count']\n",
        "print(y_train.unique())\n",
        "\n",
        "# EDA\n",
        "data = pd.concat([x_train, y_train], axis=1)\n",
        "\n",
        "## 계절 칼럼에 따른 대여 count 평균값\n",
        "print(data.groupby(['계절'])['count'].mean())\n",
        "\n",
        "## 공휴일 칼럼에 따른 대여 count 평균값\n",
        "print(data.groupby(['공휴일'])['count'].mean())\n",
        "\n",
        "## 근무일 칼럼에 따른 대여 count 평균값\n",
        "print(data.groupby(['근무일'])['count'].mean())\n",
        "\n",
        "## 날씨 칼럼에 따른 대여 count 평균값\n",
        "print(data.groupby(['날씨'])['count'].mean())\n",
        "\n",
        "# ------- 데이터 전처리 preprocessing ---------\n",
        "## train, test 모두 처리 해야 함\n",
        "\n",
        "# 결측치 처리하기 fillna()\n",
        "## 임의로 결측치 삭제하지 말 것\n",
        "## 평균, 중앙값, 상황에 따른 값\n",
        "\n",
        "# 파생변수 생성\n",
        "## 필요시 생성\n",
        "## datetiem => 년, 월, 일, 시간, 요일\n",
        "x_train['datetime'] = pd.to_datetime(x_train['datetime'])\n",
        "print(x_train.info())\n",
        "\n",
        "x_train['year'] = x_train['datetime'].dt.year\n",
        "print(x_train['year'].unique())\n",
        "\n",
        "x_train['month'] = x_train['datetime'].dt.month\n",
        "print(x_train['month'].unique())\n",
        "\n",
        "x_train['day'] = x_train['datetime'].dt.day\n",
        "print(x_train['day'].unique())\n",
        "\n",
        "x_train['hour'] = x_train['datetime'].dt.hour\n",
        "print(x_train['hour'].unique())\n",
        "\n",
        "# 0 월 ~ 6 일\n",
        "x_train['dayofweek'] = x_train['datetime'].dt.dayofweek\n",
        "print(x_train['dayofweek'].unique())\n",
        "\n",
        "## EDA \n",
        "data = pd.concat([x_train, y_train], axis=1)\n",
        "\n",
        "## year 칼럼에 따른 대여 count sum\n",
        "print(data.groupby(['year'])['count'].sum())\n",
        "\n",
        "## month 칼럼에 따른 대여 count 평균값\n",
        "print(data.groupby(['month'])['count'].mean())\n",
        "## 차이가 크지 않음\n",
        "x_train = x_train.drop(columns = ['month'])\n",
        "\n",
        "## day 칼럼에 따른 대여 count 평균값\n",
        "print(data.groupby(['day'])['count'].mean())\n",
        "## 차이가 크지 않음\n",
        "x_train = x_train.drop(columns = ['day'])\n",
        "\n",
        "## hour 칼럼에 따른 대여 count 평균값\n",
        "print(data.groupby(['hour'])['count'].mean())\n",
        "\n",
        "## dayofweek 칼럼에 따른 대여 count 평균값\n",
        "print(data.groupby(['dayofweek'])['count'].mean())\n",
        "## 차이가 크지 않음\n",
        "x_train = x_train.drop(columns = ['dayofweek'])\n",
        "\n",
        "# test 처리\n",
        "x_test['datetime'] = pd.to_datetime(x_train['datetime'])\n",
        "print(x_test.info())\n",
        "\n",
        "x_test['year'] = x_test['datetime'].dt.year\n",
        "print(x_test['year'].unique())\n",
        "\n",
        "x_test['hour'] = x_test['datetime'].dt.month\n",
        "print(x_test['hour'].unique())\n",
        "\n",
        "\n",
        "# 불필요한 컬럭 삭제 drop(columns=[])\n",
        "## PK 역할 컬럼 등 삭제\n",
        "x_train = x_train.drop(columns = ['datetime'])\n",
        "y_train = y_train.drop(columns = ['datetime'])\n",
        "\n",
        "\n",
        "# 제출용 id 삭제전 저장\n",
        "x_test_id = x_test['datetime']\n",
        "x_test = x_test.drop(columns = ['datetime'])\n",
        "print(x_train.isnull().sum())\n",
        "\n",
        "\n",
        "\n",
        "# 범주형 변수 인코딩 objedt형\n",
        "## 라벨 인코딩 LabelEncoder, 원핫인코딩  OneHotEncoder\n",
        "## 라벨 인코딩(Tree 계열의 분류 알고리즘에 사용)\n",
        "\n",
        "\n",
        "\n",
        "# 데이터 스케일링\n",
        "## 연속형 변수의 최대, 최소 분포차가 클때\n",
        "## MinMaxScaler, StandardScaler, RobustScaler\n",
        "## test는 train용으로 transform()\n",
        "## Tree 계열 필수는 아님\n",
        "\n",
        "print(x_train.describe().T)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "x_train = pd.DataFrame(scaler.fit_transform(x_train), columns=x_train.columns)\n",
        "x_test = pd.DataFrame(scaler.transform(x_test), columns=x_test.columns)\n",
        "print(x_train.describe().T)\n",
        "\n",
        "# 상관관계 확인 corr()\n",
        "## 필요 시 확인\n",
        "\n",
        "# 전처리 확인 info()\n",
        "print(x_train.info())\n",
        "print(x_test.info())\n",
        "\n",
        "# ------- 머신러닝 machine learning ---------\n",
        "\n",
        "# 평가용 데이터 분리 model_selection\n",
        "## stratify, stes_size, y값 1차원 확인\n",
        "print(y_train.value_counts()/len(y_train))\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(x_train, y_train, test_size=0.2)\n",
        "print(Y_train.value_counts()/len(Y_train))\n",
        "\n",
        "# 데이터 학습\n",
        "## fit, predict, predict_proba\n",
        "## 분류 XXXClassifier, LogisticRegression\n",
        "## 회귀(예측) XXXRegressor(XXXRegression)\n",
        "## 공통 ensemble\n",
        "## RandomForestXXX : n_estimators (default = 100), max_depth, criterion\n",
        "## criterion : 분할 품질을 측정하는 기능 ()\n",
        "### RandomForestClassifier: criterion{“gini”, “entropy”, “log_loss”}, default=”gini”\n",
        "### RandomForestRegressor: criterion{“mse”, “mae”}, / v1.2 criterion{“squared_error”, “absolute_error”}, default=”squared_error”\n",
        "## GradientBoostingXXX : n_estimators, learning_rate(default =  0.1)\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "\n",
        "#model = DecisionTreeRegressor(random_state=42) \n",
        "#model = LinearRegression(random_state=42) \n",
        "model = RandomForestRegressor(random_state=42)  \n",
        "#model = GradientBoostingClassifier(n_estmators = 100, max_depth=3) \n",
        "\n",
        "model.fit(X_train, Y_train)\n",
        "pred = model.predict(X_test)\n",
        "\n",
        "\n",
        "# 데이터 평가 metrics\n",
        "## 회귀 : MAE, MSE, RMSE, R^2, RMSE는 np.sqrt(MSE값)\n",
        "## 분류 : ROC_AUC, Accuracy(정확도), Precision(정밀도), Recall(재현율)\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "print('>>>>>> ', r2_score(Y_test, pred))\n",
        "\n",
        "\n",
        "# ------- 답안 제출 ---------\n",
        "\n",
        "# 전체학습데이터로 다시 학습\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# 제출용 예측\n",
        "pred = model.predict(x_test)\n",
        "\n",
        "\n",
        "# 답안 제출 참고\n",
        "# #아래 코드 예측변수와 수험번호를 개인별로 변경하여 활용\n",
        "#pd.DataFrame({'cust_id': x_test_data.cust_id, 'gender': pred}).to_csv('424242.csv', index=False)\n",
        "\n",
        "# 제출 최종 확인\n",
        "#print(pd.read_csv(\"data/424242.csv\"))"
      ]
    }
  ]
}